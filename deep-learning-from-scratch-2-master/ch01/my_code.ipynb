{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNの構造把握"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#線形変換の例\n",
    "import numpy as np\n",
    "W1 = np.random.randn(2, 4)\n",
    "b1 = np.random.randn(4)\n",
    "x = np.random.randn(10, 2)\n",
    "h = np.dot(x, W1)+b1\n",
    "\n",
    "# print(f\"W1={W1}\")\n",
    "# print(f\"b1={b1}\")\n",
    "# print(f\"x={x}\")\n",
    "# print(f\"h={h}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "活性化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シグモイド関数\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#入力\n",
    "x = np.random.randn(10, 2)\n",
    "#重み，バイサスの設定\n",
    "W1 = np.random.randn(2, 4)\n",
    "b1 = np.random.randn(4)\n",
    "W2 = np.random.randn(4, 3)\n",
    "b2 = np.random.randn(3)\n",
    "#推論\n",
    "h = np.dot(x, W1)+b1\n",
    "a = sigmoid(h)\n",
    "s = np.dot(a, W2) + b2\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "レイヤとしてのクラス化と順伝播の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "    def forward(self, x):\n",
    "        return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x, W) + b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2層のNNを構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "\n",
    "        #重みとバイアスの初期化\n",
    "        W1 = np.random.randn(I, H)\n",
    "        b1 = np.random.randn(H)\n",
    "        W2 = np.random.randn(H, O)\n",
    "        b2 = np.random.randn(O)\n",
    "\n",
    "        #レイヤの生成\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "\n",
    "        #すべての重みをリストにまとめる\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D']\n"
     ]
    }
   ],
   "source": [
    "#リスト同士の連結\n",
    "a=['A', 'B']\n",
    "a += ['C', 'D']\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10,2)\n",
    "model = TwoLayerNet(2, 4, 3)\n",
    "s = model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 損失関数の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クロスエントロピー損失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.params=[]\n",
    "    def forward(self, x):\n",
    "        sum = np.sum(np.exp(x), axis=1)\n",
    "        y = np.exp(x)/sum[: , np.newaxis]\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.44696686  9.89291697  9.34815466  9.61265094 10.07393199  9.52339523\n",
      "  9.44648974  9.94757747  9.39367328  9.62302867]\n",
      "[[0.80593051 0.02854737 0.16552212]\n",
      " [0.83507515 0.03005032 0.13487452]\n",
      " [0.78656524 0.02853437 0.18490039]\n",
      " [0.83290048 0.02813591 0.13896361]\n",
      " [0.86446992 0.02828223 0.10724785]\n",
      " [0.81583645 0.02861513 0.15554842]\n",
      " [0.81294782 0.02817586 0.15887632]\n",
      " [0.86297153 0.02759794 0.10943053]\n",
      " [0.76878678 0.02937214 0.20184108]\n",
      " [0.83166971 0.02831046 0.14001983]]\n"
     ]
    }
   ],
   "source": [
    "softmax = Softmax()\n",
    "y = softmax.forward(s)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MatMulノード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMul:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.x = None\n",
    "    def forward(self, x):\n",
    "        W, = self.params\n",
    "        out = np.dot(x, W)\n",
    "        self.x = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        W, =self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dW = np.dot(self.x.T, dout)\n",
    "        self.grads[0][...] = dW\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoidレイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [],[]\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = 1/(1+np.exp(x))\n",
    "        self.out = out\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout*(1.0-self.out)*self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affineレイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.dot(x, W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        W, b = self.params\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dw = np.dot(self.x.T, dout)\n",
    "        db = np.sum(dout, axis=0)\n",
    "\n",
    "        self.grads[0][...] = dw\n",
    "        self.grads[1][...] = db\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr*grads[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワークの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import Affine, Sigmoid, SoftmaxWithLoss\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "\n",
    "        #重みとバイアスの初期化\n",
    "        W1 = np.random.randn(I, H)\n",
    "        b1 = np.random.randn(H)\n",
    "        W2 = np.random.randn(H, O)\n",
    "        b2 = np.random.randn(O)\n",
    "\n",
    "        #レイヤの生成\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "\n",
    "        #すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        score = self.predict(x)\n",
    "        loss = self.loss_layer.forward(score, t)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習用のソースコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import spiral\n",
    "import matplotlib.pyplot as plt\n",
    "from two_layer_net import TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ハイパーパラメータの設定\n",
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "learning_rate = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの読み込み，モデルとオプティマイザの生成\n",
    "x, t = spiral.load_data()\n",
    "model = TwoLayerNet(input_size=2, hidden_size=hidden_size, output_size=3)\n",
    "optimizer = SGD(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|epoch 1| iter10/10|loss 1.1256062166823237\n",
      "|epoch 2| iter10/10|loss 1.1255202354489933\n",
      "|epoch 3| iter10/10|loss 1.1162613752115285\n",
      "|epoch 4| iter10/10|loss 1.1162867078413503\n",
      "|epoch 5| iter10/10|loss 1.1123000112951948\n",
      "|epoch 6| iter10/10|loss 1.1384639824108038\n",
      "|epoch 7| iter10/10|loss 1.1590961883070312\n",
      "|epoch 8| iter10/10|loss 1.1086316143023154\n",
      "|epoch 9| iter10/10|loss 1.1173305676924539\n",
      "|epoch 10| iter10/10|loss 1.1287957712269248\n",
      "|epoch 11| iter10/10|loss 1.1168438089353867\n",
      "|epoch 12| iter10/10|loss 1.108338779101816\n",
      "|epoch 13| iter10/10|loss 1.087614920049946\n",
      "|epoch 14| iter10/10|loss 1.076681386581935\n",
      "|epoch 15| iter10/10|loss 1.0442376735950387\n",
      "|epoch 16| iter10/10|loss 1.0345782626337772\n",
      "|epoch 17| iter10/10|loss 0.9572932039643971\n",
      "|epoch 18| iter10/10|loss 0.9183853210879448\n",
      "|epoch 19| iter10/10|loss 0.9241491096212101\n",
      "|epoch 20| iter10/10|loss 0.8685139076509193\n",
      "|epoch 21| iter10/10|loss 0.849380704784154\n",
      "|epoch 22| iter10/10|loss 0.8171629191788112\n",
      "|epoch 23| iter10/10|loss 0.7924414711357766\n",
      "|epoch 24| iter10/10|loss 0.7826646392986112\n",
      "|epoch 25| iter10/10|loss 0.8235432039035638\n",
      "|epoch 26| iter10/10|loss 0.7754573601774306\n",
      "|epoch 27| iter10/10|loss 0.7557857636797779\n",
      "|epoch 28| iter10/10|loss 0.7644773546985875\n",
      "|epoch 29| iter10/10|loss 0.783489908441849\n",
      "|epoch 30| iter10/10|loss 0.7507895610696304\n",
      "|epoch 31| iter10/10|loss 0.7773067036165258\n",
      "|epoch 32| iter10/10|loss 0.7650839562418821\n",
      "|epoch 33| iter10/10|loss 0.7727897179944694\n",
      "|epoch 34| iter10/10|loss 0.7819402998382252\n",
      "|epoch 35| iter10/10|loss 0.7479802970891093\n",
      "|epoch 36| iter10/10|loss 0.7449918634368046\n",
      "|epoch 37| iter10/10|loss 0.7560347486336814\n",
      "|epoch 38| iter10/10|loss 0.762136567723541\n",
      "|epoch 39| iter10/10|loss 0.7308895411004578\n",
      "|epoch 40| iter10/10|loss 0.7530268898576871\n",
      "|epoch 41| iter10/10|loss 0.7598416342022494\n",
      "|epoch 42| iter10/10|loss 0.7594443798911803\n",
      "|epoch 43| iter10/10|loss 0.7609245612331736\n",
      "|epoch 44| iter10/10|loss 0.7385235003122191\n",
      "|epoch 45| iter10/10|loss 0.7483287079215573\n",
      "|epoch 46| iter10/10|loss 0.7322123222567571\n",
      "|epoch 47| iter10/10|loss 0.7226947264484566\n",
      "|epoch 48| iter10/10|loss 0.7329453633807874\n",
      "|epoch 49| iter10/10|loss 0.7228591003722222\n",
      "|epoch 50| iter10/10|loss 0.7225109819294905\n",
      "|epoch 51| iter10/10|loss 0.7151355271138071\n",
      "|epoch 52| iter10/10|loss 0.7195462325887141\n",
      "|epoch 53| iter10/10|loss 0.7375188235491986\n",
      "|epoch 54| iter10/10|loss 0.7361580823220941\n",
      "|epoch 55| iter10/10|loss 0.7224648808897995\n",
      "|epoch 56| iter10/10|loss 0.7182891638960813\n",
      "|epoch 57| iter10/10|loss 0.7074840271194414\n",
      "|epoch 58| iter10/10|loss 0.7004036126944775\n",
      "|epoch 59| iter10/10|loss 0.7172821745385196\n",
      "|epoch 60| iter10/10|loss 0.7014167269154442\n",
      "|epoch 61| iter10/10|loss 0.7139798052248814\n",
      "|epoch 62| iter10/10|loss 0.7158390973991745\n",
      "|epoch 63| iter10/10|loss 0.70241458479173\n",
      "|epoch 64| iter10/10|loss 0.7147655630827305\n",
      "|epoch 65| iter10/10|loss 0.7258385981107363\n",
      "|epoch 66| iter10/10|loss 0.6991952628756113\n",
      "|epoch 67| iter10/10|loss 0.7149037812469097\n",
      "|epoch 68| iter10/10|loss 0.6923793329208151\n",
      "|epoch 69| iter10/10|loss 0.6950715496129249\n",
      "|epoch 70| iter10/10|loss 0.7051743201139317\n",
      "|epoch 71| iter10/10|loss 0.681889220127928\n",
      "|epoch 72| iter10/10|loss 0.693108123619465\n",
      "|epoch 73| iter10/10|loss 0.6678843529136957\n",
      "|epoch 74| iter10/10|loss 0.6795690012595998\n",
      "|epoch 75| iter10/10|loss 0.669691878190896\n",
      "|epoch 76| iter10/10|loss 0.6601032915888685\n",
      "|epoch 77| iter10/10|loss 0.6948944014779304\n",
      "|epoch 78| iter10/10|loss 0.6448714009948227\n",
      "|epoch 79| iter10/10|loss 0.6797970357896563\n",
      "|epoch 80| iter10/10|loss 0.6389928717097749\n",
      "|epoch 81| iter10/10|loss 0.6352100394457478\n",
      "|epoch 82| iter10/10|loss 0.6642182679001871\n",
      "|epoch 83| iter10/10|loss 0.6194764020308776\n",
      "|epoch 84| iter10/10|loss 0.6229674573767079\n",
      "|epoch 85| iter10/10|loss 0.612510770651763\n",
      "|epoch 86| iter10/10|loss 0.5971911133520722\n",
      "|epoch 87| iter10/10|loss 0.5988198466130638\n",
      "|epoch 88| iter10/10|loss 0.6083885307835821\n",
      "|epoch 89| iter10/10|loss 0.588113209240798\n",
      "|epoch 90| iter10/10|loss 0.5773251645421085\n",
      "|epoch 91| iter10/10|loss 0.5573829192639735\n",
      "|epoch 92| iter10/10|loss 0.5604590214222992\n",
      "|epoch 93| iter10/10|loss 0.5448990532547207\n",
      "|epoch 94| iter10/10|loss 0.5286015850570888\n",
      "|epoch 95| iter10/10|loss 0.5299314123468266\n",
      "|epoch 96| iter10/10|loss 0.5163065862636671\n",
      "|epoch 97| iter10/10|loss 0.512430857915935\n",
      "|epoch 98| iter10/10|loss 0.5016440362124133\n",
      "|epoch 99| iter10/10|loss 0.4844736823098777\n",
      "|epoch 100| iter10/10|loss 0.48000592169629297\n",
      "|epoch 101| iter10/10|loss 0.4609934880592174\n",
      "|epoch 102| iter10/10|loss 0.4540219760066977\n",
      "|epoch 103| iter10/10|loss 0.4535714177590585\n",
      "|epoch 104| iter10/10|loss 0.44299294652693855\n",
      "|epoch 105| iter10/10|loss 0.4361554171427489\n",
      "|epoch 106| iter10/10|loss 0.4104934801188964\n",
      "|epoch 107| iter10/10|loss 0.4031641890220188\n",
      "|epoch 108| iter10/10|loss 0.40761126822255767\n",
      "|epoch 109| iter10/10|loss 0.4036238903780622\n",
      "|epoch 110| iter10/10|loss 0.3995146952313422\n",
      "|epoch 111| iter10/10|loss 0.3792167407782226\n",
      "|epoch 112| iter10/10|loss 0.3750471397806638\n",
      "|epoch 113| iter10/10|loss 0.36229498494049495\n",
      "|epoch 114| iter10/10|loss 0.36757104398082374\n",
      "|epoch 115| iter10/10|loss 0.34616510526107824\n",
      "|epoch 116| iter10/10|loss 0.3448980002901156\n",
      "|epoch 117| iter10/10|loss 0.33528933507000974\n",
      "|epoch 118| iter10/10|loss 0.33807418815033236\n",
      "|epoch 119| iter10/10|loss 0.3283438143916967\n",
      "|epoch 120| iter10/10|loss 0.3351965821052375\n",
      "|epoch 121| iter10/10|loss 0.31583944005785036\n",
      "|epoch 122| iter10/10|loss 0.31740678359577434\n",
      "|epoch 123| iter10/10|loss 0.30558094499258287\n",
      "|epoch 124| iter10/10|loss 0.313067432203768\n",
      "|epoch 125| iter10/10|loss 0.30018221283884183\n",
      "|epoch 126| iter10/10|loss 0.2987418925474238\n",
      "|epoch 127| iter10/10|loss 0.2838029470706273\n",
      "|epoch 128| iter10/10|loss 0.2811840756517867\n",
      "|epoch 129| iter10/10|loss 0.28183411256599306\n",
      "|epoch 130| iter10/10|loss 0.27771459938710974\n",
      "|epoch 131| iter10/10|loss 0.2723882569863483\n",
      "|epoch 132| iter10/10|loss 0.26707712316069954\n",
      "|epoch 133| iter10/10|loss 0.27094530362207125\n",
      "|epoch 134| iter10/10|loss 0.27057245386599754\n",
      "|epoch 135| iter10/10|loss 0.2703088597272766\n",
      "|epoch 136| iter10/10|loss 0.2643726010723016\n",
      "|epoch 137| iter10/10|loss 0.26378305542245917\n",
      "|epoch 138| iter10/10|loss 0.25605019939775364\n",
      "|epoch 139| iter10/10|loss 0.25215414498445626\n",
      "|epoch 140| iter10/10|loss 0.242911129344562\n",
      "|epoch 141| iter10/10|loss 0.23945524042724547\n",
      "|epoch 142| iter10/10|loss 0.24542262746858562\n",
      "|epoch 143| iter10/10|loss 0.23667537176990053\n",
      "|epoch 144| iter10/10|loss 0.24031931061928163\n",
      "|epoch 145| iter10/10|loss 0.23361288810496234\n",
      "|epoch 146| iter10/10|loss 0.236509631799112\n",
      "|epoch 147| iter10/10|loss 0.2302540765678646\n",
      "|epoch 148| iter10/10|loss 0.22932871901830207\n",
      "|epoch 149| iter10/10|loss 0.22401693146587257\n",
      "|epoch 150| iter10/10|loss 0.22394676535578745\n",
      "|epoch 151| iter10/10|loss 0.2231075781471304\n",
      "|epoch 152| iter10/10|loss 0.22264097958236584\n",
      "|epoch 153| iter10/10|loss 0.21697683471580692\n",
      "|epoch 154| iter10/10|loss 0.21755951288880993\n",
      "|epoch 155| iter10/10|loss 0.21507058662677142\n",
      "|epoch 156| iter10/10|loss 0.20835755321509958\n",
      "|epoch 157| iter10/10|loss 0.2091354478323928\n",
      "|epoch 158| iter10/10|loss 0.20480456033012642\n",
      "|epoch 159| iter10/10|loss 0.20860699412184824\n",
      "|epoch 160| iter10/10|loss 0.19815557489605246\n",
      "|epoch 161| iter10/10|loss 0.20435571889234483\n",
      "|epoch 162| iter10/10|loss 0.1972402074622856\n",
      "|epoch 163| iter10/10|loss 0.2119889840555726\n",
      "|epoch 164| iter10/10|loss 0.19990055286420483\n",
      "|epoch 165| iter10/10|loss 0.19670798433788012\n",
      "|epoch 166| iter10/10|loss 0.19493732434411776\n",
      "|epoch 167| iter10/10|loss 0.18861275602513147\n",
      "|epoch 168| iter10/10|loss 0.1871358291328788\n",
      "|epoch 169| iter10/10|loss 0.1859257170738781\n",
      "|epoch 170| iter10/10|loss 0.18837376894472496\n",
      "|epoch 171| iter10/10|loss 0.18999546718467414\n",
      "|epoch 172| iter10/10|loss 0.18273072019428158\n",
      "|epoch 173| iter10/10|loss 0.1844137020492214\n",
      "|epoch 174| iter10/10|loss 0.18330587406258356\n",
      "|epoch 175| iter10/10|loss 0.18023455480919787\n",
      "|epoch 176| iter10/10|loss 0.17511064852464459\n",
      "|epoch 177| iter10/10|loss 0.17767416217643667\n",
      "|epoch 178| iter10/10|loss 0.17668728636135794\n",
      "|epoch 179| iter10/10|loss 0.17293847154024716\n",
      "|epoch 180| iter10/10|loss 0.17328551329855013\n",
      "|epoch 181| iter10/10|loss 0.17653792738499433\n",
      "|epoch 182| iter10/10|loss 0.1728261261811141\n",
      "|epoch 183| iter10/10|loss 0.17626893090372214\n",
      "|epoch 184| iter10/10|loss 0.17434628901735755\n",
      "|epoch 185| iter10/10|loss 0.16949071085989292\n",
      "|epoch 186| iter10/10|loss 0.17755351335716013\n",
      "|epoch 187| iter10/10|loss 0.1728569569815346\n",
      "|epoch 188| iter10/10|loss 0.16648514397547962\n",
      "|epoch 189| iter10/10|loss 0.16594153132977602\n",
      "|epoch 190| iter10/10|loss 0.1693113995126338\n",
      "|epoch 191| iter10/10|loss 0.16301106121602332\n",
      "|epoch 192| iter10/10|loss 0.16958890572080493\n",
      "|epoch 193| iter10/10|loss 0.16190682431185194\n",
      "|epoch 194| iter10/10|loss 0.15939537909039864\n",
      "|epoch 195| iter10/10|loss 0.16286032857961993\n",
      "|epoch 196| iter10/10|loss 0.16124197360055162\n",
      "|epoch 197| iter10/10|loss 0.16364914579280607\n",
      "|epoch 198| iter10/10|loss 0.1527678767991844\n",
      "|epoch 199| iter10/10|loss 0.15970328019708876\n",
      "|epoch 200| iter10/10|loss 0.1574778285151795\n",
      "|epoch 201| iter10/10|loss 0.15467694220979328\n",
      "|epoch 202| iter10/10|loss 0.15693770655217223\n",
      "|epoch 203| iter10/10|loss 0.1554765278672734\n",
      "|epoch 204| iter10/10|loss 0.1539483405879824\n",
      "|epoch 205| iter10/10|loss 0.15758367150781283\n",
      "|epoch 206| iter10/10|loss 0.15348488267419605\n",
      "|epoch 207| iter10/10|loss 0.15446293102249137\n",
      "|epoch 208| iter10/10|loss 0.14767977186639963\n",
      "|epoch 209| iter10/10|loss 0.15141489293752317\n",
      "|epoch 210| iter10/10|loss 0.14935646270420966\n",
      "|epoch 211| iter10/10|loss 0.1517051939074469\n",
      "|epoch 212| iter10/10|loss 0.1475591778682619\n",
      "|epoch 213| iter10/10|loss 0.1478514574205584\n",
      "|epoch 214| iter10/10|loss 0.1451598062679799\n",
      "|epoch 215| iter10/10|loss 0.14678399383604515\n",
      "|epoch 216| iter10/10|loss 0.14388363320088388\n",
      "|epoch 217| iter10/10|loss 0.1425976866105935\n",
      "|epoch 218| iter10/10|loss 0.14555184796511356\n",
      "|epoch 219| iter10/10|loss 0.1392242223657279\n",
      "|epoch 220| iter10/10|loss 0.13730944343188078\n",
      "|epoch 221| iter10/10|loss 0.1441059884135265\n",
      "|epoch 222| iter10/10|loss 0.14050778228166338\n",
      "|epoch 223| iter10/10|loss 0.14224984249809627\n",
      "|epoch 224| iter10/10|loss 0.14254640666896873\n",
      "|epoch 225| iter10/10|loss 0.1366720238197908\n",
      "|epoch 226| iter10/10|loss 0.13659011900484866\n",
      "|epoch 227| iter10/10|loss 0.14251665205070407\n",
      "|epoch 228| iter10/10|loss 0.13608657183237485\n",
      "|epoch 229| iter10/10|loss 0.12909966921321353\n",
      "|epoch 230| iter10/10|loss 0.13883107120690064\n",
      "|epoch 231| iter10/10|loss 0.13142337073882104\n",
      "|epoch 232| iter10/10|loss 0.13594951747222717\n",
      "|epoch 233| iter10/10|loss 0.13429273376232018\n",
      "|epoch 234| iter10/10|loss 0.13144069789855428\n",
      "|epoch 235| iter10/10|loss 0.13148269177878152\n",
      "|epoch 236| iter10/10|loss 0.12860673738419173\n",
      "|epoch 237| iter10/10|loss 0.1353920486015731\n",
      "|epoch 238| iter10/10|loss 0.13223101774593132\n",
      "|epoch 239| iter10/10|loss 0.13134628823538042\n",
      "|epoch 240| iter10/10|loss 0.137815960534109\n",
      "|epoch 241| iter10/10|loss 0.13367286871605086\n",
      "|epoch 242| iter10/10|loss 0.12860547570667233\n",
      "|epoch 243| iter10/10|loss 0.12775015207856297\n",
      "|epoch 244| iter10/10|loss 0.13002243546645464\n",
      "|epoch 245| iter10/10|loss 0.13145974901706858\n",
      "|epoch 246| iter10/10|loss 0.12796605893873653\n",
      "|epoch 247| iter10/10|loss 0.1264343911330712\n",
      "|epoch 248| iter10/10|loss 0.13201041906408506\n",
      "|epoch 249| iter10/10|loss 0.12779009853793605\n",
      "|epoch 250| iter10/10|loss 0.1304032884799827\n",
      "|epoch 251| iter10/10|loss 0.1334845629544262\n",
      "|epoch 252| iter10/10|loss 0.12453963049125047\n",
      "|epoch 253| iter10/10|loss 0.12132675691111525\n",
      "|epoch 254| iter10/10|loss 0.12286008452064749\n",
      "|epoch 255| iter10/10|loss 0.12267013423577522\n",
      "|epoch 256| iter10/10|loss 0.12312488940516735\n",
      "|epoch 257| iter10/10|loss 0.12127839505918639\n",
      "|epoch 258| iter10/10|loss 0.1246732858459719\n",
      "|epoch 259| iter10/10|loss 0.1319570980321647\n",
      "|epoch 260| iter10/10|loss 0.12026657236516311\n",
      "|epoch 261| iter10/10|loss 0.12500316552637777\n",
      "|epoch 262| iter10/10|loss 0.12062063523861213\n",
      "|epoch 263| iter10/10|loss 0.11810798686866326\n",
      "|epoch 264| iter10/10|loss 0.1268155227103573\n",
      "|epoch 265| iter10/10|loss 0.11807400896605277\n",
      "|epoch 266| iter10/10|loss 0.12014005000495157\n",
      "|epoch 267| iter10/10|loss 0.11993006486808422\n",
      "|epoch 268| iter10/10|loss 0.11732517384704763\n",
      "|epoch 269| iter10/10|loss 0.11360477597904681\n",
      "|epoch 270| iter10/10|loss 0.11888250117808821\n",
      "|epoch 271| iter10/10|loss 0.11633511040515616\n",
      "|epoch 272| iter10/10|loss 0.11825391183559268\n",
      "|epoch 273| iter10/10|loss 0.11623703569727499\n",
      "|epoch 274| iter10/10|loss 0.12322514116418934\n",
      "|epoch 275| iter10/10|loss 0.1132633426127633\n",
      "|epoch 276| iter10/10|loss 0.11580125295481199\n",
      "|epoch 277| iter10/10|loss 0.1241852704745117\n",
      "|epoch 278| iter10/10|loss 0.11289494501453375\n",
      "|epoch 279| iter10/10|loss 0.11077561346473123\n",
      "|epoch 280| iter10/10|loss 0.11431217925067254\n",
      "|epoch 281| iter10/10|loss 0.11427378474471336\n",
      "|epoch 282| iter10/10|loss 0.11731530918730079\n",
      "|epoch 283| iter10/10|loss 0.11173984745596414\n",
      "|epoch 284| iter10/10|loss 0.11382437328275703\n",
      "|epoch 285| iter10/10|loss 0.11354569974260229\n",
      "|epoch 286| iter10/10|loss 0.11082773737319437\n",
      "|epoch 287| iter10/10|loss 0.11235645391470031\n",
      "|epoch 288| iter10/10|loss 0.11698939249450464\n",
      "|epoch 289| iter10/10|loss 0.1139478128985986\n",
      "|epoch 290| iter10/10|loss 0.11472703869653127\n",
      "|epoch 291| iter10/10|loss 0.1119517943978245\n",
      "|epoch 292| iter10/10|loss 0.11252714425363779\n",
      "|epoch 293| iter10/10|loss 0.11019011632052722\n",
      "|epoch 294| iter10/10|loss 0.11147947028025722\n",
      "|epoch 295| iter10/10|loss 0.11578316334144997\n",
      "|epoch 296| iter10/10|loss 0.110222826957397\n",
      "|epoch 297| iter10/10|loss 0.1196684981477693\n",
      "|epoch 298| iter10/10|loss 0.11160268411696479\n",
      "|epoch 299| iter10/10|loss 0.10668719692739766\n",
      "|epoch 300| iter10/10|loss 0.10854954795724314\n"
     ]
    }
   ],
   "source": [
    "#学習で使用する変数\n",
    "data_size = len(x)\n",
    "max_iters = data_size//batch_size\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "loss_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    idx = np.random.permutation(data_size)\n",
    "    x = x[idx]\n",
    "    t = t[idx]\n",
    "\n",
    "    for iters in range(max_iters):\n",
    "        batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "        batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "        #勾配を求めパラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "        #定期的に学習結果を出力\n",
    "        if(iters+1) %10==0:\n",
    "            avg_loss = total_loss/loss_count\n",
    "            print(f'|epoch {epoch+1}| iter{iters+1}/{max_iters}|loss {avg_loss}')\n",
    "            loss_list.append(avg_loss)\n",
    "            total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12d5d75e0>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
